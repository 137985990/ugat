# test_enhanced_validation_integration.py - æµ‹è¯•å¢å¼ºéªŒè¯ç­–ç•¥é›†æˆ

import sys
import os
import torch
import torch.nn as nn
import numpy as np
from unittest.mock import MagicMock, patch
import tempfile
import shutil

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_enhanced_validation_manager():
    """æµ‹è¯•å¢å¼ºéªŒè¯ç®¡ç†å™¨çš„åŸºæœ¬åŠŸèƒ½"""
    from enhanced_validation_integration import EnhancedValidationManager
    
    print("ğŸ§ª æµ‹è¯•å¢å¼ºéªŒè¯ç®¡ç†å™¨...")
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•
    temp_dir = tempfile.mkdtemp()
    
    try:        # åˆå§‹åŒ–ç®¡ç†å™¨ - è®¾ç½®æ›´å°çš„è€å¿ƒåº¦ç”¨äºæµ‹è¯•
        manager = EnhancedValidationManager(
            patience=3,  # é™ä½è€å¿ƒåº¦ä»¥ä¾¿æµ‹è¯•
            min_delta=0.01,
            save_dir=temp_dir
        )
        
        # æµ‹è¯•éªŒè¯é¢‘ç‡è°ƒåº¦
        assert manager.should_validate(1) == True  # ç¬¬1ä¸ªepochåº”è¯¥éªŒè¯
        assert manager.should_validate(2) == True  # ç¬¬2ä¸ªepochåº”è¯¥éªŒè¯
        assert manager.should_validate(11) == False # ç¬¬11ä¸ªepochä¸åº”è¯¥éªŒè¯ï¼ˆæ¯2æ¬¡ï¼‰
        assert manager.should_validate(12) == True  # ç¬¬12ä¸ªepochåº”è¯¥éªŒè¯
        
        print("âœ… éªŒè¯é¢‘ç‡è°ƒåº¦æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•æŒ‡æ ‡æ›´æ–°å’Œæ—©åœé€»è¾‘
        mock_metrics = [
            {'val_loss': 1.0, 'val_accuracy': 0.7, 'val_f1_score': 0.65},
            {'val_loss': 0.8, 'val_accuracy': 0.75, 'val_f1_score': 0.7},  # æ”¹è¿›
            {'val_loss': 0.9, 'val_accuracy': 0.73, 'val_f1_score': 0.68}, # æ— æ”¹è¿›
            {'val_loss': 0.85, 'val_accuracy': 0.74, 'val_f1_score': 0.69}, # æ— æ”¹è¿›            {'val_loss': 0.87, 'val_accuracy': 0.72, 'val_f1_score': 0.67}, # æ— æ”¹è¿›
            {'val_loss': 0.88, 'val_accuracy': 0.71, 'val_f1_score': 0.66}, # æ— æ”¹è¿›
        ]
        
        should_stop = False
        for epoch, metrics in enumerate(mock_metrics, 1):
            early_stop_info = manager.update_metrics(metrics, epoch)
            should_stop = early_stop_info['should_stop']
            print(f"Epoch {epoch}: metrics={metrics}, early_stop_info={early_stop_info}")
        
        assert should_stop == True  # åº”è¯¥åœ¨ç¬¬5ä¸ªepochè§¦å‘æ—©åœ (patience=3, ä»ç¬¬2ä¸ªepochå¼€å§‹æ²¡æ”¹è¿›)
        assert manager.best_epoch == 2  # æœ€ä½³epochåº”è¯¥æ˜¯ç¬¬2ä¸ª
        
        print("âœ… æ—©åœé€»è¾‘æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•è·å–æœ€ä½³æŒ‡æ ‡æ‘˜è¦
        summary = manager.get_best_metrics_summary()
        assert summary['best_epoch'] == 2
        assert summary['early_stopped'] == True
        
        print("âœ… æŒ‡æ ‡æ‘˜è¦æµ‹è¯•é€šè¿‡")
        
    finally:
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        shutil.rmtree(temp_dir, ignore_errors=True)
    
    print("ğŸ‰ å¢å¼ºéªŒè¯ç®¡ç†å™¨æµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")


def test_mock_enhanced_validation_metrics():
    """æµ‹è¯•å¢å¼ºéªŒè¯æŒ‡æ ‡è®¡ç®—çš„æ¨¡æ‹Ÿç‰ˆæœ¬"""
    from enhanced_validation_integration import EnhancedValidationManager
    
    print("ğŸ§ª æµ‹è¯•å¢å¼ºéªŒè¯æŒ‡æ ‡è®¡ç®—...")
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„æ¨¡å‹ã€æ•°æ®åŠ è½½å™¨ç­‰
    class MockModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.linear = nn.Linear(10, 2)
        
        def forward(self, x):
            # æ¨¡æ‹Ÿè¿”å›é‡å»ºè¾“å‡ºå’Œåˆ†ç±»logits
            out = torch.randn(x.size(0), x.size(1))  # é‡å»ºè¾“å‡º
            logits = self.linear(torch.randn(10))     # åˆ†ç±»logits
            return out, logits
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    def create_mock_data_loader():
        data = []
        for _ in range(5):  # 5ä¸ªbatch
            batch = torch.randn(4, 8, 32)  # (batch_size=4, channels=8, time=32)
            labels = torch.randint(0, 2, (4,))
            mask_indices = torch.randint(0, 8, (4,))
            is_real_mask = torch.randint(0, 2, (8,)).bool()
            data.append((batch, labels, mask_indices, is_real_mask))
        return data
    
    # åˆ›å»ºæ¨¡æ‹Ÿcriterion
    class MockCriterion(nn.Module):
        def __init__(self):
            super().__init__()
            self.common_indices = [0, 1, 2]  # å‰3ä¸ªé€šé“æ˜¯common
        
        def forward(self, pred, target, channel_idx=None, is_common=False):
            return nn.MSELoss()(pred, target)
    
    # åˆ›å»ºç®¡ç†å™¨å’Œæ¨¡æ‹Ÿç»„ä»¶
    temp_dir = tempfile.mkdtemp()
    
    try:
        manager = EnhancedValidationManager(save_dir=temp_dir)
        
        # æ¨¡æ‹Ÿcompute_enhanced_validation_metricsæ–¹æ³•
        mock_metrics = {
            'val_loss': 0.5,
            'val_recon_loss': 0.3,
            'val_accuracy': 0.8,
            'val_f1_score': 0.75,
            'val_precision': 0.82,
            'val_recall': 0.78,
            'val_common_recon_loss': 0.25,
            'val_have_recon_loss': 0.35,
            'val_samples': 20
        }
        
        # æµ‹è¯•æŒ‡æ ‡æ ¼å¼
        required_keys = ['val_loss', 'val_accuracy', 'val_f1_score', 'val_common_recon_loss', 'val_have_recon_loss']
        for key in required_keys:
            assert key in mock_metrics, f"Missing required metric: {key}"
        
        print("âœ… å¢å¼ºéªŒè¯æŒ‡æ ‡æ ¼å¼æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•æ›´æ–°æŒ‡æ ‡
        early_stop_info = manager.update_metrics(mock_metrics, 1)
        
        assert 'should_stop' in early_stop_info
        assert 'epochs_no_improve' in early_stop_info
        assert 'best_epoch' in early_stop_info
        assert 'is_overfitting' in early_stop_info
        
        print("âœ… æŒ‡æ ‡æ›´æ–°æµ‹è¯•é€šè¿‡")
        
    finally:
        shutil.rmtree(temp_dir, ignore_errors=True)
    
    print("ğŸ‰ å¢å¼ºéªŒè¯æŒ‡æ ‡è®¡ç®—æµ‹è¯•é€šè¿‡ï¼")


def test_integration_with_training_loop():
    """æµ‹è¯•ä¸è®­ç»ƒå¾ªç¯çš„é›†æˆ"""
    print("ğŸ§ª æµ‹è¯•è®­ç»ƒå¾ªç¯é›†æˆ...")
    
    # æ¨¡æ‹Ÿè®­ç»ƒå¾ªç¯ä¸­çš„å…³é”®éƒ¨åˆ†
    from enhanced_validation_integration import EnhancedValidationManager
    
    temp_dir = tempfile.mkdtemp()
    
    try:
        manager = EnhancedValidationManager(
            patience=3,
            save_dir=temp_dir
        )
        
        # æ¨¡æ‹Ÿ10ä¸ªepochçš„è®­ç»ƒ
        for epoch in range(1, 11):
            # æ¨¡æ‹Ÿè®­ç»ƒæŒ‡æ ‡
            train_loss = 1.0 - epoch * 0.05  # è®­ç»ƒæŸå¤±é€æ¸ä¸‹é™
            train_acc = 0.5 + epoch * 0.03   # è®­ç»ƒå‡†ç¡®ç‡é€æ¸ä¸Šå‡
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦éªŒè¯
            if manager.should_validate(epoch):
                # æ¨¡æ‹ŸéªŒè¯æŒ‡æ ‡
                val_metrics = {
                    'val_loss': max(0.1, 1.2 - epoch * 0.1 + np.random.normal(0, 0.05)),
                    'val_accuracy': min(0.95, 0.4 + epoch * 0.04 + np.random.normal(0, 0.02)),
                    'val_f1_score': min(0.9, 0.35 + epoch * 0.04 + np.random.normal(0, 0.02)),
                    'val_precision': 0.8,
                    'val_recall': 0.75,
                    'val_common_recon_loss': 0.2,
                    'val_have_recon_loss': 0.25,
                    'val_samples': 100
                }
                
                # æ›´æ–°éªŒè¯æŒ‡æ ‡
                early_stop_info = manager.update_metrics(val_metrics, epoch)
                
                print(f"Epoch {epoch}: éªŒè¯ - val_loss={val_metrics['val_loss']:.4f}, "
                      f"val_acc={val_metrics['val_accuracy']:.4f}, "
                      f"best_epoch={early_stop_info['best_epoch']}, "
                      f"no_improve={early_stop_info['epochs_no_improve']}")
                
                # æ¨¡æ‹Ÿæ—©åœæ£€æŸ¥
                if early_stop_info['should_stop']:
                    print(f"æ—©åœè§¦å‘äºepoch {epoch}")
                    break
            else:
                print(f"Epoch {epoch}: è·³è¿‡éªŒè¯ - train_loss={train_loss:.4f}, train_acc={train_acc:.4f}")
        
        # è·å–æœ€ç»ˆæ‘˜è¦
        summary = manager.get_best_metrics_summary()
        print(f"è®­ç»ƒæ‘˜è¦: {summary}")
        
        print("âœ… è®­ç»ƒå¾ªç¯é›†æˆæµ‹è¯•é€šè¿‡")
        
    finally:
        shutil.rmtree(temp_dir, ignore_errors=True)
    
    print("ğŸ‰ è®­ç»ƒå¾ªç¯é›†æˆæµ‹è¯•å®Œæˆï¼")


def test_visualization_generation():
    """æµ‹è¯•å¯è§†åŒ–ç”Ÿæˆ"""
    print("ğŸ§ª æµ‹è¯•å¯è§†åŒ–ç”Ÿæˆ...")
    
    from enhanced_validation_integration import EnhancedValidationManager
    
    temp_dir = tempfile.mkdtemp()
    
    try:
        manager = EnhancedValidationManager(save_dir=temp_dir)
        
        # æ¨¡æ‹Ÿä¸€äº›å†å²æ•°æ®
        for epoch in range(1, 6):
            mock_metrics = {
                'val_loss': 1.0 - epoch * 0.1,
                'val_accuracy': 0.5 + epoch * 0.08,
                'val_f1_score': 0.45 + epoch * 0.07,
                'val_precision': 0.6 + epoch * 0.05,
                'val_recall': 0.55 + epoch * 0.06,
                'val_common_recon_loss': 0.5 - epoch * 0.05,
                'val_have_recon_loss': 0.6 - epoch * 0.06,
                'val_samples': 100
            }
            manager.update_metrics(mock_metrics, epoch)
        
        # ç”Ÿæˆå¯è§†åŒ–
        plot_path = os.path.join(temp_dir, "test_validation_metrics.png")
        manager.save_validation_plots(plot_path)
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
        assert os.path.exists(plot_path), "å¯è§†åŒ–æ–‡ä»¶æœªç”Ÿæˆ"
        
        print("âœ… å¯è§†åŒ–ç”Ÿæˆæµ‹è¯•é€šè¿‡")
        
    finally:
        shutil.rmtree(temp_dir, ignore_errors=True)
    
    print("ğŸ‰ å¯è§†åŒ–ç”Ÿæˆæµ‹è¯•å®Œæˆï¼")


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 60)
    print("ğŸš€ å¼€å§‹æµ‹è¯•å¢å¼ºéªŒè¯ç­–ç•¥é›†æˆ")
    print("=" * 60)
    
    try:
        test_enhanced_validation_manager()
        print()
        
        test_mock_enhanced_validation_metrics()
        print()
        
        test_integration_with_training_loop()
        print()
        
        test_visualization_generation()
        print()
        
        print("=" * 60)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¢å¼ºéªŒè¯ç­–ç•¥é›†æˆæˆåŠŸï¼")
        print("=" * 60)
        
        print("\nğŸ“‹ é›†æˆè¦ç‚¹æ€»ç»“:")
        print("1. âœ… å¢å¼ºéªŒè¯ç®¡ç†å™¨åŠŸèƒ½æ­£å¸¸")
        print("2. âœ… éªŒè¯é¢‘ç‡è°ƒåº¦å·¥ä½œæ­£ç¡®")
        print("3. âœ… å¤šæŒ‡æ ‡æ—©åœç­–ç•¥æœ‰æ•ˆ")
        print("4. âœ… è¿‡æ‹Ÿåˆæ£€æµ‹æœºåˆ¶è¿è¡Œ")
        print("5. âœ… å¯è§†åŒ–ç”ŸæˆåŠŸèƒ½æ­£å¸¸")
        print("6. âœ… è®­ç»ƒå¾ªç¯é›†æˆæ— é—®é¢˜")
        
        print("\nğŸ”§ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("1. åœ¨å®é™…è®­ç»ƒä¸­æµ‹è¯•å¢å¼ºéªŒè¯ç­–ç•¥")
        print("2. æ ¹æ®å®é™…æ•°æ®è°ƒæ•´éªŒè¯é¢‘ç‡è°ƒåº¦")
        print("3. å¾®è°ƒæ—©åœç­–ç•¥çš„æƒé‡å‚æ•°")
        print("4. ç›‘æ§å¢å¼ºéªŒè¯æŒ‡æ ‡çš„å˜åŒ–è¶‹åŠ¿")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
