# enhanced_validation.py - å¢å¼ºéªŒè¯é›†ç­–ç•¥

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, List, Tuple
import logging
import os

class ValidationTracker:
    """éªŒè¯é›†æ€§èƒ½è·Ÿè¸ªå™¨"""
    
    def __init__(self, patience: int = 10, min_delta: float = 1e-6, mode: str = 'min'):
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.best_score = float('inf') if mode == 'min' else float('-inf')
        self.counter = 0
        self.best_epoch = 0
        self.history = []
        
    def update(self, score: float, epoch: int) -> bool:
        """
        æ›´æ–°éªŒè¯åˆ†æ•°
        Returns: True if should stop early, False otherwise
        """
        self.history.append(score)
        
        if self.mode == 'min':
            is_better = score < (self.best_score - self.min_delta)
        else:
            is_better = score > (self.best_score + self.min_delta)
        
        if is_better:
            self.best_score = score
            self.best_epoch = epoch
            self.counter = 0
            return False
        else:
            self.counter += 1
            return self.counter >= self.patience
    
    def get_stats(self) -> Dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'best_score': self.best_score,
            'best_epoch': self.best_epoch,
            'counter': self.counter,
            'patience': self.patience,
            'should_stop': self.counter >= self.patience,
            'improvement_rate': self._calculate_improvement_rate()
        }
    
    def _calculate_improvement_rate(self) -> float:
        """è®¡ç®—æ”¹è¿›ç‡"""
        if len(self.history) < 10:
            return 0.0
        
        recent = np.mean(self.history[-5:])
        past = np.mean(self.history[-10:-5])
        
        if self.mode == 'min':
            return (past - recent) / past if past > 0 else 0.0
        else:
            return (recent - past) / past if past > 0 else 0.0

class EnhancedValidationLoop:
    """å¢å¼ºéªŒè¯å¾ªç¯"""
    
    def __init__(self, model, criterion, device, mask_indices, 
                 enable_detailed_metrics: bool = True):
        self.model = model
        self.criterion = criterion
        self.device = device
        self.mask_indices = mask_indices
        self.enable_detailed_metrics = enable_detailed_metrics
        
    def evaluate(self, dataloader, return_detailed: bool = False) -> Dict:
        """
        æ‰§è¡Œå®Œæ•´çš„éªŒè¯è¯„ä¼°
        
        Args:
            dataloader: éªŒè¯æ•°æ®åŠ è½½å™¨
            return_detailed: æ˜¯å¦è¿”å›è¯¦ç»†æŒ‡æ ‡
            
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        self.model.eval()
        
        total_losses = {}
        total_samples = 0
        predictions_list = []
        targets_list = []
        labels_list = []
        logits_list = []
        
        with torch.no_grad():
            for batch, labels, mask_idx, is_real_mask in dataloader:
                batch = batch.to(self.device)
                labels = labels.to(self.device)
                is_real_mask = is_real_mask.to(self.device)
                
                # åº”ç”¨mask
                from train import mask_channel
                masked, mask_idx = mask_channel(batch, self.mask_indices)
                
                batch_size, C, T = batch.size()
                batch_predictions = []
                batch_logits = []
                
                # é€æ ·æœ¬é¢„æµ‹
                for i in range(batch_size):
                    window = masked[i].t()
                    out, logits = self.model(window)
                    batch_predictions.append(out.unsqueeze(0))
                    batch_logits.append(logits.unsqueeze(0))
                
                predictions = torch.cat(batch_predictions, dim=0)
                logits_batch = torch.cat(batch_logits, dim=0)
                
                # è®¡ç®—æŸå¤±
                if hasattr(self.criterion, 'common_indices'):
                    # å¤šæ¨¡æ€æŸå¤±
                    loss_dict = self._compute_multimodal_loss(
                        predictions, batch, logits_batch, labels, is_real_mask
                    )
                else:
                    # æ ‡å‡†æŸå¤±
                    loss_dict = self._compute_standard_loss(
                        predictions, batch, logits_batch, labels, is_real_mask
                    )
                
                # ç´¯ç§¯æŸå¤±
                for key, value in loss_dict.items():
                    if key not in total_losses:
                        total_losses[key] = 0.0
                    total_losses[key] += value.item() * batch_size
                
                total_samples += batch_size
                
                # æ”¶é›†è¯¦ç»†ä¿¡æ¯
                if return_detailed:
                    predictions_list.append(predictions.cpu())
                    targets_list.append(batch.cpu())
                    labels_list.append(labels.cpu())
                    logits_list.append(logits_batch.cpu())
        
        # å¹³å‡æŸå¤±
        for key in total_losses:
            total_losses[key] /= total_samples
        
        # è®¡ç®—å‡†ç¡®ç‡
        if 'classification_loss' in total_losses:
            total_losses['accuracy'] = self._compute_accuracy(
                torch.cat(logits_list) if logits_list else None,
                torch.cat(labels_list) if labels_list else None
            )
        
        if return_detailed and self.enable_detailed_metrics:
            total_losses.update(self._compute_detailed_metrics(
                predictions_list, targets_list, labels_list, logits_list
            ))
        
        return total_losses
    
    def _compute_multimodal_loss(self, predictions, targets, logits, labels, is_real_mask):
        """è®¡ç®—å¤šæ¨¡æ€æŸå¤±"""
        common_indices = self.criterion.common_indices
        batch_size, C, T = predictions.shape
        
        total_loss = 0.0
        common_loss = 0.0
        have_loss = 0.0
        ce_loss = nn.CrossEntropyLoss()
        
        for i in range(batch_size):
            real_channels = is_real_mask[i]
            recon_loss_i = 0.0
            common_loss_i = 0.0
            have_loss_i = 0.0
            common_count = 0
            have_count = 0
            
            for c in range(C):
                target = targets[i, c, :]
                pred = predictions[i, c, :]
                
                is_common_channel = c in common_indices
                
                if is_common_channel:
                    loss_c = self.criterion(pred, target, channel_idx=c, is_common=True)
                    common_loss_i += loss_c
                    common_count += 1
                elif real_channels[c]:
                    loss_c = self.criterion(pred, target, channel_idx=c, is_common=False)
                    have_loss_i += loss_c
                    have_count += 1
            
            if common_count > 0:
                common_loss_i /= common_count
            if have_count > 0:
                have_loss_i /= have_count
            
            recon_loss_i = common_loss_i + have_loss_i
            cls_loss_i = ce_loss(logits[i:i+1], labels[i:i+1])
            
            total_loss += recon_loss_i + cls_loss_i
            common_loss += common_loss_i
            have_loss += have_loss_i
        
        return {
            'total_loss': total_loss / batch_size,
            'reconstruction_loss': (common_loss + have_loss) / batch_size,
            'common_loss': common_loss / batch_size,
            'have_loss': have_loss / batch_size,
            'classification_loss': ce_loss(logits, labels)
        }
    
    def _compute_standard_loss(self, predictions, targets, logits, labels, is_real_mask):
        """è®¡ç®—æ ‡å‡†æŸå¤±"""
        batch_size, C, T = predictions.shape
        total_recon_loss = 0.0
        
        for i in range(batch_size):
            real_channels = is_real_mask[i]
            recon_loss_i = 0.0
            real_count = 0
            
            for c in range(C):
                if real_channels[c]:
                    target = targets[i, c, :]
                    pred = predictions[i, c, :]
                    recon_loss_i += self.criterion(pred, target)
                    real_count += 1
            
            if real_count > 0:
                recon_loss_i /= real_count
            
            total_recon_loss += recon_loss_i
        
        ce_loss = nn.CrossEntropyLoss()
        cls_loss = ce_loss(logits, labels)
        
        return {
            'total_loss': total_recon_loss / batch_size + cls_loss,
            'reconstruction_loss': total_recon_loss / batch_size,
            'classification_loss': cls_loss
        }
    
    def _compute_accuracy(self, logits, labels):
        """è®¡ç®—åˆ†ç±»å‡†ç¡®ç‡"""
        if logits is None or labels is None:
            return 0.0
        
        pred_classes = logits.argmax(dim=-1)
        return (pred_classes == labels).float().mean().item()
    
    def _compute_detailed_metrics(self, predictions_list, targets_list, labels_list, logits_list):
        """è®¡ç®—è¯¦ç»†æŒ‡æ ‡"""
        if not predictions_list:
            return {}
        
        # æ‹¼æ¥æ‰€æœ‰æ‰¹æ¬¡
        all_predictions = torch.cat(predictions_list, dim=0)
        all_targets = torch.cat(targets_list, dim=0)
        
        # è®¡ç®—é‡å»ºæŒ‡æ ‡
        mse = torch.mean((all_predictions - all_targets) ** 2).item()
        mae = torch.mean(torch.abs(all_predictions - all_targets)).item()
        
        # è®¡ç®—ä¿¡å™ªæ¯”
        signal_power = torch.mean(all_targets ** 2).item()
        noise_power = torch.mean((all_predictions - all_targets) ** 2).item()
        snr = 10 * np.log10(signal_power / (noise_power + 1e-8))
        
        return {
            'mse': mse,
            'mae': mae,
            'snr_db': snr,
            'signal_power': signal_power,
            'noise_power': noise_power
        }

def create_enhanced_validation_strategy(config):
    """åˆ›å»ºå¢å¼ºéªŒè¯ç­–ç•¥"""
    
    patience = config.get('patience', 20)
    min_delta = config.get('min_delta', 1e-6)
    
    # åˆ›å»ºå¤šä¸ªè·Ÿè¸ªå™¨
    trackers = {
        'total_loss': ValidationTracker(patience, min_delta, 'min'),
        'reconstruction_loss': ValidationTracker(patience, min_delta, 'min'),
        'classification_loss': ValidationTracker(patience, min_delta, 'min'),
        'accuracy': ValidationTracker(patience, min_delta, 'max'),
    }
    
    # å¦‚æœä½¿ç”¨å¤šæ¨¡æ€æŸå¤±ï¼Œæ·»åŠ é¢å¤–è·Ÿè¸ªå™¨
    if config.get('loss_config', {}).get('type') == 'multimodal':
        trackers.update({
            'common_loss': ValidationTracker(patience, min_delta, 'min'),
            'have_loss': ValidationTracker(patience, min_delta, 'min'),
        })
    
    return trackers

def enhanced_training_loop_with_validation(model, train_loader, val_loader, optimizer, 
                                          criterion, device, mask_indices, config):
    """å¢å¼ºçš„è®­ç»ƒå¾ªç¯ï¼ŒåŒ…å«å®Œæ•´éªŒè¯ç­–ç•¥"""
    
    # åˆ›å»ºéªŒè¯ç»„ä»¶
    val_loop = EnhancedValidationLoop(model, criterion, device, mask_indices)
    trackers = create_enhanced_validation_strategy(config)
    
    epochs = config.get('epochs', 100)
    log_dir = config.get('log_dir', 'Logs')
    ckpt_dir = config.get('ckpt_dir', 'Checkpoints')
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=5, verbose=True
    )
    
    best_val_loss = float('inf')
    best_model_state = None
    
    print("ğŸš€ å¼€å§‹å¢å¼ºéªŒè¯ç­–ç•¥è®­ç»ƒ")
    
    for epoch in range(1, epochs + 1):
        # è®­ç»ƒé˜¶æ®µ
        from train import train_phased
        train_metrics = train_phased(
            model, train_loader, optimizer, criterion, device, mask_indices
        )
        
        # éªŒè¯é˜¶æ®µ
        val_metrics = val_loop.evaluate(val_loader, return_detailed=(epoch % 10 == 0))
        
        # æ›´æ–°è·Ÿè¸ªå™¨
        should_stop = False
        for metric_name, tracker in trackers.items():
            if metric_name in val_metrics:
                metric_should_stop = tracker.update(val_metrics[metric_name], epoch)
                if metric_name == 'total_loss':  # ä¸»è¦æŒ‡æ ‡
                    should_stop = metric_should_stop
        
        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step(val_metrics['total_loss'])
        current_lr = optimizer.param_groups[0]['lr']
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_metrics['total_loss'] < best_val_loss:
            best_val_loss = val_metrics['total_loss']
            best_model_state = model.state_dict().copy()
            torch.save(best_model_state, os.path.join(ckpt_dir, 'best_model.pth'))
            print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (Epoch {epoch}, Val Loss: {best_val_loss:.6f})")
        
        # è¯¦ç»†æ—¥å¿—
        log_message = f"[ENHANCED] Epoch {epoch}: "
        log_message += f"train_loss={train_metrics.get('total_loss', 0):.6f}, "
        log_message += f"val_loss={val_metrics['total_loss']:.6f}, "
        log_message += f"val_acc={val_metrics.get('accuracy', 0):.4f}, "
        log_message += f"lr={current_lr:.6e}"
        
        if 'common_loss' in val_metrics:
            log_message += f", common_loss={val_metrics['common_loss']:.6f}"
            log_message += f", have_loss={val_metrics['have_loss']:.6f}"
        
        logging.info(log_message)
        print(log_message)
        
        # æ—©åœæ£€æŸ¥
        if should_stop:
            total_tracker = trackers['total_loss']
            print(f"ğŸ›‘ æ—©åœè§¦å‘! æœ€ä½³epoch: {total_tracker.best_epoch}, "
                  f"æœ€ä½³åˆ†æ•°: {total_tracker.best_score:.6f}")
            break
        
        # æ¯10ä¸ªepochæ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡
        if epoch % 10 == 0:
            print(f"\nğŸ“Š Epoch {epoch} éªŒè¯ç»Ÿè®¡:")
            for metric_name, tracker in trackers.items():
                stats = tracker.get_stats()
                print(f"  {metric_name}: å½“å‰={val_metrics.get(metric_name, 0):.6f}, "
                      f"æœ€ä½³={stats['best_score']:.6f} (Epoch {stats['best_epoch']}), "
                      f"åœæ»={stats['counter']}/{stats['patience']}")
    
    # åŠ è½½æœ€ä½³æ¨¡å‹
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
        print(f"ğŸ† åŠ è½½æœ€ä½³æ¨¡å‹ (Val Loss: {best_val_loss:.6f})")
    
    return model, trackers

if __name__ == "__main__":
    print("å¢å¼ºéªŒè¯ç­–ç•¥æ¨¡å—")
    print("ä¸»è¦åŠŸèƒ½:")
    print("âœ… æ­£ç¡®çš„éªŒè¯é›†è®¡ç®—ï¼ˆä¸æ›´æ–°å‚æ•°ï¼‰")
    print("âœ… å¤šæŒ‡æ ‡æ—©åœç­–ç•¥")
    print("âœ… è¯¦ç»†çš„éªŒè¯æŒ‡æ ‡è·Ÿè¸ª")
    print("âœ… æœ€ä½³æ¨¡å‹è‡ªåŠ¨ä¿å­˜")
    print("âœ… å­¦ä¹ ç‡è°ƒåº¦ä¼˜åŒ–")
    print("âœ… å¤šæ¨¡æ€æŸå¤±æ”¯æŒ")
