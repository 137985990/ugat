#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯•ä¼˜åŒ–é…ç½®æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import yaml
import torch
import sys
import os

def test_configuration():
    print("ğŸ”§ æµ‹è¯•ä¼˜åŒ–é…ç½®...")
    
    # æ£€æŸ¥CUDA
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name()}")
        print(f"æ˜¾å­˜æ€»é‡: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        print(f"å½“å‰æ˜¾å­˜ä½¿ç”¨: {torch.cuda.memory_allocated() / 1024**3:.1f} GB")
    
    # åŠ è½½é…ç½®
    with open('config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    print(f"\nğŸ“Š ä¼˜åŒ–é…ç½®å‚æ•°:")
    print(f"  - Batch Size: {config.get('batch_size', 'N/A')}")
    print(f"  - Learning Rate: {config.get('lr', 'N/A')}")
    print(f"  - Num Workers: {config.get('num_workers', 'N/A')}")
    print(f"  - Mixed Precision: {config.get('use_mixed_precision', 'N/A')}")
    print(f"  - Pin Memory: {config.get('pin_memory', 'N/A')}")
    print(f"  - Prefetch Factor: {config.get('prefetch_factor', 'N/A')}")
    
    # æ£€æŸ¥æ··åˆç²¾åº¦æ”¯æŒ
    try:
        from torch.cuda.amp import GradScaler, autocast
        print(f"  - AMPæ”¯æŒ: âœ… å¯ç”¨")
        scaler = GradScaler()
        print(f"  - GradScaleråˆ›å»º: âœ… æˆåŠŸ")
    except ImportError as e:
        print(f"  - AMPæ”¯æŒ: âŒ ä¸å¯ç”¨ ({e})")
    
    # æµ‹è¯•æ•°æ®åŠ è½½å™¨é…ç½®
    print(f"\nğŸš€ æ•°æ®åŠ è½½å™¨æµ‹è¯•:")
    try:
        from torch.utils.data import DataLoader, TensorDataset
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = torch.randn(100, 32, 320)
        test_labels = torch.randint(0, 2, (100,))
        test_dataset = TensorDataset(test_data, test_labels)
        
        # åˆ›å»ºé«˜æ€§èƒ½DataLoader
        test_loader = DataLoader(
            test_dataset,
            batch_size=config.get('batch_size', 64),
            num_workers=min(config.get('num_workers', 8), 4),  # é™åˆ¶æµ‹è¯•ç”¨çš„workeræ•°
            pin_memory=config.get('pin_memory', True),
            prefetch_factor=config.get('prefetch_factor', 4),
            persistent_workers=True,
            shuffle=True
        )
        
        # æµ‹è¯•ä¸€ä¸ªbatch
        for batch_data in test_loader:
            batch_x, batch_y = batch_data
            print(f"  - æµ‹è¯•batchå½¢çŠ¶: {batch_x.shape}")
            print(f"  - æ ‡ç­¾å½¢çŠ¶: {batch_y.shape}")
            break
        
        print(f"  - DataLoaderåˆ›å»º: âœ… æˆåŠŸ")
        
    except Exception as e:
        print(f"  - DataLoaderæµ‹è¯•: âŒ å¤±è´¥ ({e})")
    
    print(f"\nâœ¨ é…ç½®æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    test_configuration()
